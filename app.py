from dotenv import load_dotenv

load_dotenv()

# app.py
import os
import streamlit as st

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


# =========================
# 1) ç”»é¢è¨­å®š
# =========================
st.set_page_config(page_title="LangChain LLM Webã‚¢ãƒ—ãƒª", page_icon="ğŸ¤–", layout="centered")

st.title("ğŸ¤– LangChain Ã— LLM ã‹ã‚“ãŸã‚“Webã‚¢ãƒ—ãƒª")
st.caption("å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã«æ¸¡ã—ã¦ã€å›ç­”ã‚’ç”»é¢ã«è¡¨ç¤ºã—ã¾ã™ã€‚å°‚é–€å®¶ã®ç¨®é¡ã‚‚ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§åˆ‡ã‚Šæ›¿ãˆã§ãã¾ã™ã€‚")

with st.expander("ã“ã®Webã‚¢ãƒ—ãƒªã®æ¦‚è¦ãƒ»æ“ä½œæ–¹æ³•", expanded=True):
    st.markdown(
        """
        - **ä½¿ã„æ–¹**
        1. ã€Œå°‚é–€å®¶ã®ç¨®é¡ã€ã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸ã³ã¾ã™ï¼ˆA / Bï¼‰ã€‚
        2. ä¸‹ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
        3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€LLMã®å›ç­”ãŒä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

        - **ãƒã‚¤ãƒ³ãƒˆ**
        - ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠã«å¿œã˜ã¦ã€LLMã«æ¸¡ã™ **ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆå½¹å‰²æŒ‡ç¤ºï¼‰** ãŒåˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™ã€‚
        - LangChainã‚’ä½¿ã£ã¦ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿ã€LLMã«æŠ•ã’ã¦ã„ã¾ã™ã€‚
        """
    )

st.divider()

# =========================
# 2) å°‚é–€å®¶ï¼ˆA/Bï¼‰å®šç¾©
#    â€»ã€ŒAã€ã€ŒBã€ã¯é¸æŠè‚¢åã¨ã—ã¦ä¿æŒã—ã¤ã¤ã€ä¸­èº«ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã§ä½œæˆ
# =========================
EXPERT_SYSTEM_MESSAGES = {
    "Aï¼ˆPythonå®¶åº­æ•™å¸«ï¼‰": (
        "ã‚ãªãŸã¯è¦ªåˆ‡ã§å®Ÿè·µçš„ãªPythonå®¶åº­æ•™å¸«ã§ã™ã€‚"
        "åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚‹ã‚ˆã†ã«ã€çŸ­ã„ä¾‹ã‚’äº¤ãˆãªãŒã‚‰æ‰‹é †ã‚’æ˜ç¢ºã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        "ä¸ç¢ºã‹ãªç‚¹ã¯æ¨æ¸¬ã›ãšã€ç¢ºèªã™ã¹ãç‚¹ã‚’è³ªå•ã—ã¦ãã ã•ã„ã€‚"
    ),
    "Bï¼ˆã‚­ãƒ£ãƒªã‚¢ç›¸è«‡ã‚³ãƒ¼ãƒï¼‰": (
        "ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ç›¸è«‡ã®ãƒ—ãƒ­ã®ã‚³ãƒ¼ãƒã§ã™ã€‚"
        "ç›¸æ‰‹ã®çŠ¶æ³ã‚’æ•´ç†ã—ã€é¸æŠè‚¢ã‚’æç¤ºã—ã€æ¬¡ã®ä¸€æ­©ãŒå…·ä½“åŒ–ã™ã‚‹ã‚ˆã†ã«æ”¯æ´ã—ã¦ãã ã•ã„ã€‚"
        "æ±ºã‚ã¤ã‘ãšã€å¿…è¦ã«å¿œã˜ã¦å‰æç¢ºèªã®è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚"
    ),
}

# =========================
# 3) LLMå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆèª²é¡Œè¦ä»¶ï¼‰
#    ã€Œå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€ã¨ã€Œãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã®é¸æŠå€¤ã€ã‚’å¼•æ•°ã§å—ã‘ã€
#    LLMã‹ã‚‰ã®å›ç­”ã‚’æˆ»ã‚Šå€¤ã¨ã—ã¦è¿”ã™
# =========================
def ask_llm(input_text: str, expert_choice: str) -> str:
    """
    Args:
        input_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
        expert_choice: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠå€¤ï¼ˆEXPERT_SYSTEM_MESSAGESã®ã‚­ãƒ¼ï¼‰
    Returns:
        LLMã®å›ç­”ï¼ˆæ–‡å­—åˆ—ï¼‰
    """
    system_message = EXPERT_SYSTEM_MESSAGES.get(expert_choice, "ã‚ãªãŸã¯æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")

    # Streamlit Community Cloud ã§ã¯ st.secrets ã« OPENAI_API_KEY ã‚’å…¥ã‚Œã‚‹ã®ãŒå®šçŸ³
    # ï¼ˆSettings -> Secretsï¼‰
    api_key = None
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
    else:
        api_key = os.environ.get("OPENAI_API_KEY")

    if not api_key:
        return "OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Streamlitã®Secretsã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚"

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.4,
        api_key=api_key,
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("human", "{user_input}"),
        ]
    )

    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"user_input": input_text})


# =========================
# 4) UIï¼ˆãƒ©ã‚¸ã‚ª + å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼‰
# =========================
expert_choice = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„ï¼ˆA / Bï¼‰",
    options=list(EXPERT_SYSTEM_MESSAGES.keys()),
    horizontal=True,
)

with st.form(key="input_form"):
    user_text = st.text_area(
        "å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆè³ªå•ãƒ»ç›¸è«‡ãªã©ï¼‰",
        placeholder="ä¾‹ï¼‰Pythonã§è¾æ›¸ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ / è»¢è·ã™ã‚‹ã‹è¿·ã£ã¦ã„ã¾ã™â€¦ ãªã©",
        height=140,
    )
    submitted = st.form_submit_button("é€ä¿¡")

if submitted:
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚ä½•ã‹å…¥åŠ›ã—ã¦ã‹ã‚‰é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            answer = ask_llm(user_text, expert_choice)

        st.subheader("å›ç­”çµæœ")
        st.write(answer)

st.divider()
st.caption("â€» Streamlit Community Cloud ã§ã¯ã€Secrets ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
